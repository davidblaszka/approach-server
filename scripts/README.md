

## Crawler

- Load html
- Parse data
- Load data into SQL database

### Loading html


### Parse data
- likely store in mongodb or something. Can be local instance to start, RDS instance later
- optional key-value pairs
- Keep track of the location "tree"


#### ETL job to standardized data format
Maybe don't need this, just calling out a multi-step processing pipeline way be helpful


### Load data into sql
Probably a scala script to read from one DB and write to another

